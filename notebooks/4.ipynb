{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c = pd.read_csv(\"../data/classification/X_train_c.csv\")\n",
    "X_test_c = pd.read_csv(\"../data/classification/X_test_c.csv\")\n",
    "y_train_c = pd.read_csv(\"../data/classification/y_train_c.csv\")\n",
    "y_test_c = pd.read_csv(\"../data/classification/y_test_c.csv\")\n",
    "X_train_r = pd.read_csv(\"../data/regression/X_train_r.csv\")\n",
    "X_test_r = pd.read_csv(\"../data/regression/X_test_r.csv\")\n",
    "y_train_r = pd.read_csv(\"../data/regression/y_train_r.csv\")\n",
    "y_test_r = pd.read_csv(\"../data/regression/y_test_r.csv\")\n",
    "X_train_c.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "X_test_c.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "y_train_c.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "y_test_c.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "X_train_r.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "X_test_r.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "y_train_r.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "y_test_r.drop(columns = [\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>AirportFrom</th>\n",
       "      <th>AirportTo</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113014</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.338712</td>\n",
       "      <td>0.906228</td>\n",
       "      <td>0.122137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.626712</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.777467</td>\n",
       "      <td>0.164885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272918</td>\n",
       "      <td>0.106870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.140411</td>\n",
       "      <td>0.037671</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307908</td>\n",
       "      <td>0.580153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.222603</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.283415</td>\n",
       "      <td>0.119084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Airline  AirportFrom  AirportTo  DayOfWeek      Time    Length\n",
       "0  0.000000     0.113014   0.342466   0.338712  0.906228  0.122137\n",
       "1  0.764706     0.626712   0.047945   0.462383  0.777467  0.164885\n",
       "2  0.176471     0.547945   0.328767   0.333333  0.272918  0.106870\n",
       "3  0.470588     0.140411   0.037671   0.500000  0.307908  0.580153\n",
       "4  0.823529     0.205479   0.222603   0.500000  0.283415  0.119084"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.943457</td>\n",
       "      <td>0.176076</td>\n",
       "      <td>-1.101291</td>\n",
       "      <td>-1.122350</td>\n",
       "      <td>-1.046903</td>\n",
       "      <td>-1.074952</td>\n",
       "      <td>-0.174238</td>\n",
       "      <td>-0.315593</td>\n",
       "      <td>1.229620</td>\n",
       "      <td>-0.588987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334558</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.118808</td>\n",
       "      <td>-0.184588</td>\n",
       "      <td>-0.567341</td>\n",
       "      <td>-0.451714</td>\n",
       "      <td>-0.422063</td>\n",
       "      <td>1.839611</td>\n",
       "      <td>-0.269103</td>\n",
       "      <td>-0.320862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.964222</td>\n",
       "      <td>0.176076</td>\n",
       "      <td>-0.205550</td>\n",
       "      <td>2.334907</td>\n",
       "      <td>2.233057</td>\n",
       "      <td>2.353882</td>\n",
       "      <td>-0.174238</td>\n",
       "      <td>-0.315593</td>\n",
       "      <td>1.229620</td>\n",
       "      <td>-0.588987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334558</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.118808</td>\n",
       "      <td>-0.184588</td>\n",
       "      <td>-0.567341</td>\n",
       "      <td>2.213789</td>\n",
       "      <td>-0.422063</td>\n",
       "      <td>-0.543593</td>\n",
       "      <td>-0.269103</td>\n",
       "      <td>-0.320862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.565295</td>\n",
       "      <td>-1.225920</td>\n",
       "      <td>-0.205550</td>\n",
       "      <td>-0.438008</td>\n",
       "      <td>-0.378763</td>\n",
       "      <td>-0.544128</td>\n",
       "      <td>-0.174238</td>\n",
       "      <td>-0.315593</td>\n",
       "      <td>1.229620</td>\n",
       "      <td>-0.588987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334558</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.118808</td>\n",
       "      <td>-0.184588</td>\n",
       "      <td>-0.567341</td>\n",
       "      <td>-0.451714</td>\n",
       "      <td>-0.422063</td>\n",
       "      <td>1.839611</td>\n",
       "      <td>-0.269103</td>\n",
       "      <td>-0.320862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001949</td>\n",
       "      <td>-0.034223</td>\n",
       "      <td>0.242320</td>\n",
       "      <td>0.201895</td>\n",
       "      <td>0.167897</td>\n",
       "      <td>0.187548</td>\n",
       "      <td>-0.174238</td>\n",
       "      <td>-0.315593</td>\n",
       "      <td>-0.813259</td>\n",
       "      <td>1.697829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334558</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.118808</td>\n",
       "      <td>-0.184588</td>\n",
       "      <td>1.762607</td>\n",
       "      <td>-0.451714</td>\n",
       "      <td>-0.422063</td>\n",
       "      <td>-0.543593</td>\n",
       "      <td>-0.269103</td>\n",
       "      <td>-0.320862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.817403</td>\n",
       "      <td>-0.174423</td>\n",
       "      <td>-0.653420</td>\n",
       "      <td>-0.820173</td>\n",
       "      <td>-0.795266</td>\n",
       "      <td>-0.831060</td>\n",
       "      <td>-0.174238</td>\n",
       "      <td>-0.315593</td>\n",
       "      <td>1.229620</td>\n",
       "      <td>-0.588987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334558</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.118808</td>\n",
       "      <td>-0.184588</td>\n",
       "      <td>-0.567341</td>\n",
       "      <td>-0.451714</td>\n",
       "      <td>-0.422063</td>\n",
       "      <td>-0.543593</td>\n",
       "      <td>3.716048</td>\n",
       "      <td>-0.320862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.943457  0.176076 -1.101291 -1.122350 -1.046903 -1.074952 -0.174238   \n",
       "1  2.964222  0.176076 -0.205550  2.334907  2.233057  2.353882 -0.174238   \n",
       "2 -0.565295 -1.225920 -0.205550 -0.438008 -0.378763 -0.544128 -0.174238   \n",
       "3  0.001949 -0.034223  0.242320  0.201895  0.167897  0.187548 -0.174238   \n",
       "4 -0.817403 -0.174423 -0.653420 -0.820173 -0.795266 -0.831060 -0.174238   \n",
       "\n",
       "          7         8         9  ...        16        17        18        19  \\\n",
       "0 -0.315593  1.229620 -0.588987  ... -0.334558 -0.234216 -0.118808 -0.184588   \n",
       "1 -0.315593  1.229620 -0.588987  ... -0.334558 -0.234216 -0.118808 -0.184588   \n",
       "2 -0.315593  1.229620 -0.588987  ... -0.334558 -0.234216 -0.118808 -0.184588   \n",
       "3 -0.315593 -0.813259  1.697829  ... -0.334558 -0.234216 -0.118808 -0.184588   \n",
       "4 -0.315593  1.229620 -0.588987  ... -0.334558 -0.234216 -0.118808 -0.184588   \n",
       "\n",
       "         20        21        22        23        24        25  \n",
       "0 -0.567341 -0.451714 -0.422063  1.839611 -0.269103 -0.320862  \n",
       "1 -0.567341  2.213789 -0.422063 -0.543593 -0.269103 -0.320862  \n",
       "2 -0.567341 -0.451714 -0.422063  1.839611 -0.269103 -0.320862  \n",
       "3  1.762607 -0.451714 -0.422063 -0.543593 -0.269103 -0.320862  \n",
       "4 -0.567341 -0.451714 -0.422063 -0.543593  3.716048 -0.320862  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(26,)),\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 64)                1728      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,353\n",
      "Trainable params: 4,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1345/1345 [==============================] - 2s 894us/step - loss: 2723038.2500\n",
      "Epoch 2/50\n",
      "1345/1345 [==============================] - 1s 868us/step - loss: 1218867.0000\n",
      "Epoch 3/50\n",
      "1345/1345 [==============================] - 1s 937us/step - loss: 1029588.5625\n",
      "Epoch 4/50\n",
      "1345/1345 [==============================] - 1s 930us/step - loss: 1004560.5000\n",
      "Epoch 5/50\n",
      "1345/1345 [==============================] - 1s 954us/step - loss: 1031506.0625\n",
      "Epoch 6/50\n",
      "1345/1345 [==============================] - 1s 980us/step - loss: 1007078.4375\n",
      "Epoch 7/50\n",
      "1345/1345 [==============================] - 1s 917us/step - loss: 978907.9375\n",
      "Epoch 8/50\n",
      "1345/1345 [==============================] - 1s 924us/step - loss: 986946.8750\n",
      "Epoch 9/50\n",
      "1345/1345 [==============================] - 1s 928us/step - loss: 983281.3750\n",
      "Epoch 10/50\n",
      "1345/1345 [==============================] - 1s 954us/step - loss: 997656.0625\n",
      "Epoch 11/50\n",
      "1345/1345 [==============================] - 1s 924us/step - loss: 989760.7500\n",
      "Epoch 12/50\n",
      "1345/1345 [==============================] - 1s 954us/step - loss: 965997.6250\n",
      "Epoch 13/50\n",
      "1345/1345 [==============================] - 1s 933us/step - loss: 985788.8750\n",
      "Epoch 14/50\n",
      "1345/1345 [==============================] - 1s 920us/step - loss: 971408.6250\n",
      "Epoch 15/50\n",
      "1345/1345 [==============================] - 1s 941us/step - loss: 968846.5000\n",
      "Epoch 16/50\n",
      "1345/1345 [==============================] - 1s 928us/step - loss: 945495.8750\n",
      "Epoch 17/50\n",
      "1345/1345 [==============================] - 1s 912us/step - loss: 971535.4375\n",
      "Epoch 18/50\n",
      "1345/1345 [==============================] - 1s 918us/step - loss: 934158.6875\n",
      "Epoch 19/50\n",
      "1345/1345 [==============================] - 1s 936us/step - loss: 951410.8125\n",
      "Epoch 20/50\n",
      "1345/1345 [==============================] - 1s 909us/step - loss: 962401.6875\n",
      "Epoch 21/50\n",
      "1345/1345 [==============================] - 1s 957us/step - loss: 947606.7500\n",
      "Epoch 22/50\n",
      "1345/1345 [==============================] - 1s 1ms/step - loss: 929053.6250\n",
      "Epoch 23/50\n",
      "1345/1345 [==============================] - 1s 922us/step - loss: 940552.7500\n",
      "Epoch 24/50\n",
      "1345/1345 [==============================] - 1s 929us/step - loss: 951356.0625\n",
      "Epoch 25/50\n",
      "1345/1345 [==============================] - 1s 922us/step - loss: 953650.9375\n",
      "Epoch 26/50\n",
      "1345/1345 [==============================] - 1s 941us/step - loss: 931403.2500\n",
      "Epoch 27/50\n",
      "1345/1345 [==============================] - 1s 884us/step - loss: 933332.1875\n",
      "Epoch 28/50\n",
      "1345/1345 [==============================] - 1s 865us/step - loss: 923503.0000\n",
      "Epoch 29/50\n",
      "1345/1345 [==============================] - 1s 851us/step - loss: 912837.6250\n",
      "Epoch 30/50\n",
      "1345/1345 [==============================] - 1s 836us/step - loss: 908712.5625\n",
      "Epoch 31/50\n",
      "1345/1345 [==============================] - 1s 855us/step - loss: 936420.6875\n",
      "Epoch 32/50\n",
      "1345/1345 [==============================] - 1s 894us/step - loss: 935480.0625\n",
      "Epoch 33/50\n",
      "1345/1345 [==============================] - 1s 914us/step - loss: 933915.5000\n",
      "Epoch 34/50\n",
      "1345/1345 [==============================] - 1s 929us/step - loss: 898043.1875\n",
      "Epoch 35/50\n",
      "1345/1345 [==============================] - 1s 934us/step - loss: 828748.1250\n",
      "Epoch 36/50\n",
      "1345/1345 [==============================] - 1s 949us/step - loss: 833314.0000\n",
      "Epoch 37/50\n",
      "1345/1345 [==============================] - 1s 914us/step - loss: 798643.8750\n",
      "Epoch 38/50\n",
      "1345/1345 [==============================] - 1s 933us/step - loss: 773297.1250\n",
      "Epoch 39/50\n",
      "1345/1345 [==============================] - 1s 914us/step - loss: 774618.5625\n",
      "Epoch 40/50\n",
      "1345/1345 [==============================] - 1s 916us/step - loss: 758731.8750\n",
      "Epoch 41/50\n",
      "1345/1345 [==============================] - 1s 933us/step - loss: 755327.4375\n",
      "Epoch 42/50\n",
      "1345/1345 [==============================] - 1s 915us/step - loss: 737669.5000\n",
      "Epoch 43/50\n",
      "1345/1345 [==============================] - 1s 934us/step - loss: 744144.3125\n",
      "Epoch 44/50\n",
      "1345/1345 [==============================] - 1s 918us/step - loss: 743865.1875\n",
      "Epoch 45/50\n",
      "1345/1345 [==============================] - 1s 913us/step - loss: 720548.5625\n",
      "Epoch 46/50\n",
      "1345/1345 [==============================] - 1s 905us/step - loss: 703740.3750\n",
      "Epoch 47/50\n",
      "1345/1345 [==============================] - 1s 919us/step - loss: 705974.5625\n",
      "Epoch 48/50\n",
      "1345/1345 [==============================] - 1s 943us/step - loss: 699993.3125\n",
      "Epoch 49/50\n",
      "1345/1345 [==============================] - 1s 974us/step - loss: 685190.6250\n",
      "Epoch 50/50\n",
      "1345/1345 [==============================] - 1s 927us/step - loss: 667987.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1323b4d7100>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.fit(X_train_r, y_train_r, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/337 [==============================] - 0s 693us/step\n",
      "338.93221804656685\n",
      "337/337 [==============================] - 0s 696us/step\n",
      "1253075.3568998505\n",
      "337/337 [==============================] - 0s 627us/step\n",
      "0.0976663313462076\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test_r, model_regression.predict(X_test_r)))\n",
    "print(mean_squared_error(y_test_r, model_regression.predict(X_test_r)))\n",
    "print(mean_absolute_percentage_error(y_test_r, model_regression.predict(X_test_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 1 / y_train_c[y_train_c==0].shape[0]\n",
    "w1 = 1 / y_train_c[y_train_c==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14956/14956 [==============================] - 21s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 2/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 3/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 4/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 5/25\n",
      "14956/14956 [==============================] - 18s 1ms/step - loss: 1.4484e-06\n",
      "Epoch 6/25\n",
      "14956/14956 [==============================] - 20s 1ms/step - loss: 1.4484e-06\n",
      "Epoch 7/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 8/25\n",
      "14956/14956 [==============================] - 20s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 9/25\n",
      "14956/14956 [==============================] - 20s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 10/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 11/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 12/25\n",
      "14956/14956 [==============================] - 20s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 13/25\n",
      "14956/14956 [==============================] - 20s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 14/25\n",
      "14956/14956 [==============================] - 18s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 15/25\n",
      "14956/14956 [==============================] - 18s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 16/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 17/25\n",
      "14956/14956 [==============================] - 21s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 18/25\n",
      "14956/14956 [==============================] - 22s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 19/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4484e-06\n",
      "Epoch 20/25\n",
      "14956/14956 [==============================] - 21s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 21/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4484e-06\n",
      "Epoch 22/25\n",
      "14956/14956 [==============================] - 18s 1ms/step - loss: 1.4484e-06\n",
      "Epoch 23/25\n",
      "14956/14956 [==============================] - 20s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 24/25\n",
      "14956/14956 [==============================] - 19s 1ms/step - loss: 1.4485e-06\n",
      "Epoch 25/25\n",
      "14956/14956 [==============================] - 21s 1ms/step - loss: 1.4485e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1323f2e0af0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(6,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(X_train_c, y_train_c, epochs=25,\n",
    "                           class_weight={0: w0, 1: w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3739/3739 [==============================] - 3s 713us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.around(model_classification_1.predict(X_test_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.00      0.00     59824\n",
      "           1       0.50      1.00      0.67     59824\n",
      "\n",
      "    accuracy                           0.50    119648\n",
      "   macro avg       0.47      0.50      0.34    119648\n",
      "weighted avg       0.47      0.50      0.34    119648\n",
      "\n",
      "[[  124 59700]\n",
      " [  154 59670]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_c, y_pred))\n",
    "print(confusion_matrix(y_test_c, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.save('../models/RegressionModel')\n",
    "model_classification_1.save('../models/ClassificationModel1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ˜‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Component:\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "    def backward(self, gradient_loss_respect_y: np.ndarray, optimizer) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def value(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "    def gradient(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def update(self, weights: np.ndarray, bias: np.ndarray, gradient_loss_respect_weights: np.ndarray, gradient_loss_respect_bias: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Component):\n",
    "    def __init__(self, x_shape, y_shape):\n",
    "        self.weights = np.random.randn(y_shape, x_shape)\n",
    "        self.bias = np.zeros(y_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.weights @ x + self.bias\n",
    "    \n",
    "    def backward(self, gradient_loss_respect_y, optimizer):\n",
    "        gradient_loss_respect_x = self.weights.T @ gradient_loss_respect_y\n",
    "        gradient_loss_respect_w = gradient_loss_respect_y.reshape(np.size(gradient_loss_respect_y), -1) @ self.x.reshape(-1, np.size(self.x))\n",
    "        gradient_loss_respect_b = gradient_loss_respect_y\n",
    "        self.weights, self.bias = optimizer.update(self.weights, self.bias, gradient_loss_respect_w, gradient_loss_respect_b)\n",
    "        return gradient_loss_respect_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Component):\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / ((1 + np.exp(-x)) + 1e-30)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.__sigmoid(x)\n",
    "    \n",
    "    def backward(self, gradient_loss_respect_y):\n",
    "        s = self.__sigmoid(self.x)\n",
    "        return gradient_loss_respect_y * (s * (1 - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Component):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def backward(self, gradient_loss_respect_y):\n",
    "        return gradient_loss_respect_y * (1 * (self.x > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Component):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def backward(self, gradient_loss_respect_y):\n",
    "        return gradient_loss_respect_y * (1 - np.tanh(self.x) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Component):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = np.exp(x - np.amax(x, 1).reshape(x.shape[0],1)) / np.exp(x - np.amax(x, 1).reshape(x.shape[0],1)).sum(axis=1, keepdims=True) + 1e-30\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, gradient_loss_respect_y):\n",
    "        return (((np.identity(np.size(self.y)) - self.y.T) * self.y) @ gradient_loss_respect_y).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Loss):\n",
    "    def value(self, y_true, y_pred):\n",
    "        return np.sum((y_pred - y_true) ** 2) / y_pred.size\n",
    "    \n",
    "    def gradient(self, y_true, y_pred):\n",
    "        return np.sum(2 * (y_pred - y_true)) / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseBCE(Loss):\n",
    "    def value(self, y_true, y_pred):\n",
    "        return -y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred)\n",
    "    \n",
    "    def gradient(self, y_true, y_pred):\n",
    "        return (1 - y_true) / (1 - y_pred + 1e-30) - y_true / (y_pred + 1e-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCE(Loss):\n",
    "    def __one_hot_encode(self, y_true, y_pred: np.ndarray) -> np.ndarray:\n",
    "        class_label = y_true\n",
    "        y_true = np.zeros_like(y_pred)\n",
    "        y_true[class_label] = 1\n",
    "        return y_true\n",
    "        \n",
    "    def value(self, y_true, y_pred):\n",
    "        y_true = self.__one_hot_encode(y_true, y_pred)\n",
    "        return -float(np.sum(y_true * np.log(y_pred)))\n",
    "    \n",
    "    def gradient(self, y_true, y_pred):\n",
    "        p = y_pred[1]\n",
    "        return (1 - y_true) / (1 - p + 1e-30) - y_true / (p + 1e-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential():\n",
    "    def __init__(self, layers: np.ndarray[Component], optimizer: Optimizer, loss: Loss):\n",
    "        self.layers = layers\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y = x\n",
    "        for layer in self.layers:\n",
    "            y = layer.forward(y)\n",
    "        return y\n",
    "    \n",
    "    def fit(self, X_train, y_train, epochs = 100):\n",
    "        for i in range(epochs):\n",
    "            for j in range(len(X_train)):\n",
    "                output = self.predict(X_train[i])\n",
    "                gradient_error_respect_x = self.loss.gradient(y_train[i], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    gradient_error_respect_x = layer.backward(gradient_error_respect_x, self.optimizer)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(Optimizer):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def update(self, weights, bias, gradient_loss_respect_weights, gradient_loss_respect_bias):\n",
    "        weights = self.learning_rate + gradient_loss_respect_weights\n",
    "        bias = self.learning_rate + gradient_loss_respect_bias\n",
    "        return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro = Sequential(layers=[\n",
    "    Dense(26, 8),\n",
    "    Relu(),\n",
    "    Dense(8, 4),\n",
    "    Relu(),\n",
    "    Dense(4, 2),\n",
    "    Dense(2, 1)\n",
    "], optimizer=GradientDescent(learning_rate=0.00001), loss=MSE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_r \u001b[39m=\u001b[39m X_train_r\u001b[39m.\u001b[39;49mto_numpy()\n\u001b[0;32m      2\u001b[0m y_train_r \u001b[39m=\u001b[39m y_train_r\u001b[39m.\u001b[39mto_numpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "X_train_r = X_train_r.to_numpy()\n",
    "y_train_r = y_train_r.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neuro\u001b[39m.\u001b[39;49mfit(X_train_r, y_train_r)\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36mSequential.fit\u001b[1;34m(self, X_train, y_train, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m         gradient_error_respect_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mgradient(y_train[i], output)\n\u001b[0;32m     18\u001b[0m         \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m---> 19\u001b[0m             gradient_error_respect_x \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward(gradient_error_respect_x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer)\n\u001b[0;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mDense.backward\u001b[1;34m(self, gradient_loss_respect_y, optimizer)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m, gradient_loss_respect_y, optimizer):\n\u001b[1;32m---> 11\u001b[0m     gradient_loss_respect_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m gradient_loss_respect_y\n\u001b[0;32m     12\u001b[0m     gradient_loss_respect_w \u001b[39m=\u001b[39m gradient_loss_respect_y\u001b[39m.\u001b[39mreshape(np\u001b[39m.\u001b[39msize(gradient_loss_respect_y), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx))\n\u001b[0;32m     13\u001b[0m     gradient_loss_respect_b \u001b[39m=\u001b[39m gradient_loss_respect_y\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "neuro.fit(X_train_r, y_train_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
